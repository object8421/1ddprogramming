
何谓PC,这要从PC的起源说起:
计算机俗称电脑[1. 就跟摩托车叫电驴一样，这来源于港台的说法，据说是旧式CRT显式器的后盖部像人的后脑勺].我们平常谈到的计算机就是指PC.
当然,计算机不光指PC,还可以指服务器,大型机,我们无意去为分别这里面的区别花费时间,这纯粹是一种历史叫法(叫PC的那些计算机叫PC,不叫PC的计算机叫其它名字而已[2. 换言之,除pc外的计算机不叫PC,可能叫“各种各样名字的计算机”,比如SUN的叫sunrpc,compad的叫alpha,而PC,是Inter针对个人用户推出的,特有的,一种计算机架构,这个架构,不只是CPU架构,硬件架构,还包含组成这个架构的软件意义上的体系.]).在不加特别说明的情况下,本书作为编程教学书以下部分我谈到计算机就是指PC.我们是对PC编程.
PC的概念更多地是一个历史概念而非范畴概念,历史上第一代(注意并非第一台)PC是指1981年8月IBM推出的第一代个人计算机,称为IBM PC,它配备了intel的8088 CPU和Microsoft的MS-DOS,从这里开始,Intel确立了它PC行业的CPU霸主地位,微软也慢慢成为了软件领域的巨无霸.Wintel组合出现[3. ibm是ihm,microsoft是i soft m(os是通用软件)].
当然,IBM是卖电脑的,Intel是做CPU的,而微软是搞软件的,这三者业务领域不一样.但电脑就是从这个时候开始进入大众生活的,在这之前是一些巨型机,科研设备机器,以及个人爱好者研制的雏形所谓“计算机”.正是这样的发展,带来了计算机向PC发展的态势(硬件上的,软件上的,总体架构上的).
关于这其中的种种历史,存在有一些趣闻,比如:
【硬件上的】:
据可靠不可靠小道消息,第一台计算机其实是由一个叫毛利的人发明的而不是教科书中普遍谈到的那个巨大的家伙ENIAC.
【软件上的】:
50,60年代某段时间一种叫CP/M的操作系统差点取代MSDOS而使它所属的公司成为IBM的合作伙伴.
MSDOS实际上只是一层壳.它是改PCDOS来的.而DOS实际上并非微软所产,它的作者早就死了.
作为软硬结合的典范。微软曾和ibm合作开发os2。但由于对操作系统的分歧太大。微软后来独自去开发os,这导致出现了以后的windows。
苹果图形界面拉开了计算机图形时代的到来.
【架构上的】:
CPU是有架构的[4. Intel有专门的一本厚厚的书介绍它的CPU架构的],AMD和Intel主频之争从来都没停过,具体请参见各种资料..


图灵机与冯氏模型
=============





图灵机与图灵形式理论
-------------


大约在许多许多年之前，那时计算机还没有出现，人们使用天然的计算机-我们自己本身，来存储信息（人脑），传输信息（嘴巴，肢体），产生实现的功效（劳动使物），那时，人们把自己称为“人”，人们相信他们自己掌有最无上的能力，相信他们才是宇宙最高智能，其它类似人的，能帮人完成诸如“帮我记一些事，帮我扎个绳记个事，帮我扛一个包”的一切东西，人们给它取过一个名字，称为“机器”。机的泛义就是器物，然而它代表一种能在某方面替代人能协助人完成某事的“类人器物”，由于机器具大的实用性，几百万来人们争相竞走，发明这样的“机”，以图造福后人也是被后人记住，于是出现了打火机，飞机，蒸气机，铲土机这样的东西。

但是这样的东西，虽然能协助人类完成一些他们做不了的事，但是还是显得尚不够智能，飞机飞得再高，它也只是外在表现为一些机电和一个操纵盘(最初的飞机是直升机)，内在表现为能量的东西，它并不会在将要坠毁时自动地做出相应措施，飞机的飞行遵守的是物理学的和数学的，然而它是大自然的规则，顺应规则并不等于具有智慧，况且，这些还是人来完成的（否则驾驶员作用何在？），飞机本身永远不会主动，换言之，它们还是“物”。

后来出现了机器人，这种复杂的器具，涉及到数学，物理，动力学，然而，人们甚至自己都不能使自己相信“数学就是智能”。

从飞机到机器人，人们以为他们发明的是类人的伙伴，结果证明，茫茫宇宙，只有自己和具有同样特征的自己的对话，和发生在他们之间的欺骗和自我欺骗。对自己本身智能的不认识，是人类最大的悲哀，更别论发明一种类人的“机”，只要它做不到类人的主动能动性，那么，智能只能止于模拟。（现代计算机，人工神经网络也是如此），我们只能承认：如果一种机能被一种假智能驱动帮助人们干好事，那么它就是智能的。（同飞机，机器人一样，人们往往用数学和物理上的手段，来完成智能系统的建设） 计算机的发明，就源于对所谓智能的研究。也许这句话更应该换个说法，即，现代计算机模型的产生源于对自动控制(自动机理论)和人工智能(机器人)的研究. 18世纪，有个叫图灵的人，说了一句话“说如果把人关一个房间里，如果在不了解任何情况的情况下，他能凭自己所知独立解决一些问题，那么它就是智能的”，然后就去着手发明了一种自动机，全称是图灵自动机，图灵等一帮人[1. 图灵(1912-1954),战后开始从事早期计算机的开发,它的兴趣在于研究机器体现的人工智能,比如自动性,这一帮人还包括他的老师,就是那个发明Lisp形式系统的人(后人据此发明了LISP机). 图灵对智能的研究在计算机之后，那时计算机作为专用系统已有一定的智能性，图灵想从AI领域突破，以使计算机变成纯粹多用，而且智能的类人机器]开始早期现代计算机研究的时候真正意义上的计算机尚未产生,那时各种各样的机器都出自科学们一手惊鸿的杰作(是的,它们只能称为机器,而不是计算机,自然这种机器就不可能是现代意义上的某种计算机,比如PC.------ 而且,历史上地,它们大都用在了毁灭的战争上[2. ENICA就是二战中用来破解德国人密码用的，CPU硬件的本质是大量有着开与关状态的与门电路，这点现代计算机与ENICA相同，但ENICA并没有一个CPU，CPU是现代计算机才有的。ENICA出现在图灵理论前，但CPU代表的现代PC计算机出现在图灵理论后。],而不是属于计算机它们自己的工业化流程中,比如,二战中经图灵一手破解的德国密码机就是一例), 这也就是说，图灵的时代，早期的那些计算机尚没有一个统一的概念（人们称它们为各式各样的机），所以更没有一个在数学上可以成立的统一理论基础.而他的图灵形式理论,即是对计算机领域的此种基础贡献,但,根据图灵本人更深一些的理想来说,其实更多的是对人工智能的探测.

为了实现这个目的,他们需要借助数学(数学是一切科学的基础)的手段,从数学上进行突破,将数学概念进行构造,使其形式化,图灵首先是一个数学家,和破译专家,因此有人说计算机是数学思想失败(第三次数学危机,希尔伯特理论体系被哥德尔击跨[3. 哥德尔（Goedel）证明了数学公理完全性和一致性的非现实性(不现实)，这对当时数学界普遍持定的认为数学可以表达绝对真理的论点提出了严重的挑战。然而，是否有方法证实一个定理的真实性呢？图林另辟蹊径对这个问题进行了探索。他把所有的数学运算归结到基本的计算，而这种计算简单得连机器都能操纵，这种机器被称为“图灵机”（the Turing machine）。])的产物.计算机是喝着数学(或和电子学)的乳汁长大的.图灵造出了图灵数学,丘奇造出了函数理论(将数学函数进行“可构造,可计算化”),图灵与丘氏最开始的区别,只可能是数学上的,然后才是编程风格上的.

图灵机是一种通用自动机器的概念模型和数学模型,它并非首先指代某种完美的现实存在物，飞机，机器人它们虽然不是真人智能，但他们至少还是现实存在，而这种图灵机(实际上是有限自动机的一种，它跟以后出现的AI领域中的无限自动机对立)，它甚至连现实的“机”都不是(只有将形体抽象化了，而且具体在历史所处，我们才能在抽象和逻辑上讨论它带来的意义)。 在概念上,这种机器有极其简单的形式(它有一个二端无限延伸的纸带作为存储装置,输入,输出和状态转移函数是一个机器的三要素,这三要素组合并变形的过程就是组成一个图灵机的工作原型所需的全部东西),只要给它有意义的输入,它就能产生足够丰富的变形并可表达图灵机能解决的丰富问题(可解决,诸如计算函数模拟硬件这样的问题,这些问题统统都用一个词来概括“算法”[4. 19世纪和20世纪早期的数学家、逻辑学家在定义算法上出现了困难.20世纪的英国数学家图灵提出了著名的图灵论题,并提出一种假想的计算机的抽象模型,这个模型被称为图灵机.图灵机的出现解决了算法定义的难题,图灵的思想对算法的发展起到了重要的作用]),图灵机作为自动机形式理论之一,因为它揭示并解决了现代计算机在抽象层次运行的本质即形式计算(图灵机的运作原理被称为形式计算,是离散数学自动机的一部分, 通过测试的机器就叫图灵完备,,所有通过图灵完备的机器,这说明它们有同样的一类能力,可以解决等价的算法..可以解决同样的问题.[5. 参见选读部分,算法的证明,和停机问题.]).这对计算机发展的意义不言而喻,因为它使计算机[6. 硬件,以及它对软件上的直接影响]真正有了理论学科,从此计算机进入了它的工业化,而图灵因为他的这个贡献被称为计算机之父.各种形式的自动计算机理论随后在那个时代发展开来.

>>计算智能不是真正的智能，但它的确是我们需要的智能，数学基础的严密加编程对机器功能进行抽象的灵活表现，使PC可以模拟我们日常生活甚至是全领域所需要的全部智能。即，计算智能主要体现在二方面，第一个是硬件平台即PC的建设，另一个是对编程的支持，这促成了用编程来完成（软件）平台建设自身。

这里只讲平台，后来会谈到编程。


从图灵机到实现图灵形式理论的实际存在物
-------------

上面说到，图灵机是一种自动机和智能产品的形式理论，那么利用这种理论实现的实物之一(作为一种理论，图灵理论可用电子计算机，机械设备，或其它形式的能量装置完成)，就是现代计算机。

>当图灵机的数学理论被实现在计算机中时，就成了：有限指令对存储进行操作。只要硬件的速度够快。计算机就能运行和和表达任何抽象（硬件的，或软件上的）。这就是图灵原理,而且，图灵原理指出，这种有限的形式其实可以表达任何图灵理论支持的问题(只要它是有限步完成的，不会导致停机问题)。以后我们会知道，这就是算法要解决的问题。

如果说图灵机阐述的是一种泛义上的自动机(它绝不仅仅限于实现计算机),那么冯氏模型[7. 冯诺依?蔓,是图灵那一时代的人,是我提到的“那一帮人”中的其中一个.他跟图灵一样,也因它的贡献被称为计算机之父。（而图灵不但是计算机之父，也是人工智能之父，计算机是人工智能产物）]就是专门针对计算机的自动机理论了,以前的机器(在可编程电脑出现之前),指令是硬化的,要为某机器编程相当于重置整个机器.而冯氏机设置了二大部件,一是执行部件(CPU),一是存储部件(主存)[8. 当然,还有IO部分,但对这二者的讨论似乎包括了IO]. CPU和内存(它们靠电工作,是电脑中的电字所指所在, 从硬件上来看,PC的运行过程在外在上就表现为通电状态下的CPU从同样通电状态下的主存里取指令并译码执行的过程,它们不是智能设备,而是机电设备)才是PC的硬件仅需的二个东西.只要有CPU和内存,一个系统在硬件上就是一个基本的PC(其它的都是周边设备,它们只是用来扩展PC的功能),只不过现代意义上的PC,除了提供CPU和内存,支持“计算”功能之外,还支持其它组件 - 比如IO子系统,图形子系统,这些附加组件中的一些成为现代PC必不可少的部件,比如IO(无法想象不能输出信息和输入信息的PC有什么用,当然,我把IO等同于“输出信息和输入信息”是不够严谨的),Filesystem(无法想象没有硬盘没有文件的PC有什么用),UI(无法想象不能给用户提供一个可以观看输出的屏幕和界面的PC有什么用),NETWORK(无法想象不能跟其它PC联网的机器有什么用[9. 于是,现代意义上的PC被定义为 “具有微处理单元,具有IO和存储部件的机器”,这也成为其它类PC的智能设备的原型,比如手机,它们往往参照PC模型.在硬件和软件上都拥有大致相同的解决方案.]).

以上这些,只是硬件构架上的表层,冯氏机在理论上的精神在于"指令存储,顺序执行",在冯氏模型下,执行指令的机制和存储指令的机制是分开的,要换一套程序不需要更换指令系统,因为程序是被内存存储的,取指令器是从RAM中随机取出[10. 某个时钟周期内,某条活动指令总是会在某个内存位置待命,随机的意思就是直接指定内存地址并从里面取码进行执行,冯氏保证这个过程,这是冯氏努力的全部.],并不用预先在内存位置固化程序,然后通过控制和地址总线交互存取到内存,这样CPU只负责执行,对于实现不同的程序,它可以只用一套指令系统(CPU支持一定的指令,和一定的类型).而这种指令组成的程序(可能是用户写的一段机器程序或汇编程序),本质上是一套,有机的,顺序的,确定的指令集,任何时候,机器都(提供一套机制)保证CPU从RAM中随机取到这样一条指令并执行它,完成指令的执行和数据的存储,这究竟是种什么样的过程呢? 这就不得不说下CPU和内存是如何在底层工作的.

小总结
-------------

上面说了,整个冯氏PC系统是以CPU作为执行单元和主存作为存储单元为它二大主要架构部件的,(靠沟通他们二者之间的地址线和控制线通信),,即冯氏计算机,就是一旦开始工作(开机),就只会做“指令被不断取出并译码执行的顺序与确定过程[11. 所以本质上它其实并不智能,PC只是一台高速自动机而已],”的机器.这也是冯氏计算机“计算”的意义所在[12. CPU中最主要的二个部件是控制器和运算器,计算机之所以被称为计算机,是因为它提供了形式计算,还是CPU里面的逻辑和算术运算呢,当然是前者.实际上运算器和逻辑器的地位就像协处理器一样,是CPU不必要的组件,是CPU扩展它的功能加的电路板.]. 不管如何,请记住.这种最终反应在软件层面上的Task running support才是PC的功能本质,IO系统,图形系统,文件系统,声音系统,网络系统,全是PC的附加功能组件和附加硬件.它们虽然不是一个纯意义上的PC的必要组成部分,但是对于一个现代PC来说,它们几乎是不可缺少的.只是当它们被附加到PC上时,PC需要为与它们的通讯工作提供额外的接口,而且这些智能系统都有自己的控制器,但是没有自己的指令和内存,所以它们共享PC的处理能力和表数据能力,才能在PC中发挥作用,(于是这些附加功能)表现为PC的功能和应用. 所以,其实,CPU不但处理它自己的事情(执行指令,调用数据)而且是作为整个PC的总控制中心存在的(它还协调其它周边设备并完成一部分他们完成不了的工作),简单地说,PC的运行过程等同于CPU执行的过程,因为所谓IO[13. IO部件并不直接与CPU交互,计算机系统中只有内存与总线与CPU直接交互,IO通过IO接口跟CPU交互],其实一定都是有CPU参与并受它主导的, CPU不但接管了内存管理这些他进行计算时应管的事,还接管了其它硬件,比如它把显存归入它的管理统一跟主内存编码,而且它管理与其它硬件的通讯,比如它把硬件功能归为它的中断例程并把其中断处理程序的地址统一跟内存编码.CPU的执行过程就是在硬件时钟的一个恒定周期中 (有一个时钟发生器指导CPU不断地运行)不断调用指令变换其指令状态,输入输出则是这些内存二进制表示[14. 因此整个PC做的工作都是某种意义上的IO]. 总而言之,冯氏架构中,CPU统冶了整个机器,内存二把手,其它硬件则是被它管理和统治的,这样整个PC才发挥作用.

用CPU管理内存
-------------

冯氏计算机硬件工程的任务就是 “产生一种不断从内存中取出代码并译码执行的计算机”。这句话直接透露出的最重要的东西，就是CPU与内存的联系了。 CPU管理内存的硬件基础是它的MMU和ALU单元，及地址总线和数据总线[15. 我们知道CPU虽然自己处理数据,但他同时还主要做着一种IO的动作,键盘,鼠标组成的IO系统要通过接入CPU才能发挥其作用,因为它们没有自己的CPU,CPU管理IO的硬件被集成在主板上一块被称为芯片组的地方,当然,这些IO设备指鼠标,键盘等,硬盘这样的大件被IDE控制着.],其中地址总线是负责寻址机制的通道,而数据总线的数量就表示CPU（借助MMU的作用）能一次性处理的数据通道, 因为真实内存地址总是有限的，虽然可能在内存形成一个跟“真实内存线性空间”直接对应的“指令数据空间”，但这样一套“寻址与表示”未免太浪费CPU和内存是超高速设备的能力了。为了产生一种完善的，物尽其用的“寻址和表示”机制，故需要在软件上(比如OS的实现中)进行抽象。 况且，地址线数与数据线性往往长度不一[16. 这是故意的,还是技术因素造成的呢?],这就导致了CPU的寻址跟处理产生了一对矛盾,地址线决定了它能看到(CPU能使用到的)和管理到的内存总量(物理地址),而数据线决定了它能一次性“连续地[17. 一下子地,在硬件意义上的一个单位步骤里]”处理的数据长度和能表示的地址形式(逻辑地址),,,这就是表示(逻辑地址形式)和实际内存(物理地址)上的矛盾.故也需要抽象。 逻辑表示是寄存器能表示的地址形式,真实地址是系统装配的内存量,抽象的任务就是要完成这二大地址机制间的转换。由于MMU和ALU都是CPU中的高速处理单元，只有它们足够快，就可产生一种“抽象逻辑空间”的假象。 撇开其它因素,我们就事论事来讨论这个矛盾,20位地址线可以使用2^20个最小内存单元即1MB的内存空间(这就是说使得这种CPU的一个任务理论上可使用至多1MB的线性空间,因为它只能“直接”寻址到这么大的地儿)但16位CPU中的寄存器只能表示前16位[18. CPU是用寄存器来表示地址的,这就是说虽然CPU能看到整整1MB的空间,但他一口吃不下其中的最小一个单元,因为它首先都不能直接表达这个单元].因此CPU要表达和要用尽这1MB的空间,不能以直接线性对应的方式来表达.除非数据线多于或等于地址线. “间接”的方法就是设置另一层抽象.可令16位先表达一个大小为64KB的段,1MB的内存刚好等于1MB / 64KB倍数个这样大小的段.在这种情况下,内存就不再是绝对线性的了[19. 当然,实际上所有内存都是线性的,这里说的是分段之后的逻辑情况下,而且你不用担心CPU认不认识这样的划段法因为它的确认识,下面会谈到一个实模式的东西],而是被划分成了一个一个的段(在段内才是线性的),16位用来表示段内的每个最小内存单元,空出的4位不再用来表达内存本身,可以用来表达段本身. 以上讨论的情况是8086CPU在实模式运行的存储管理逻辑,即从逻辑地址(CPU要形成任务用到的地址形式)到真实物理地址的编码(实际机器有的地址),这中间要经过一个变换,CPU负责这个转换.无论在多少长度的地址线和多少长度的数据线产生矛盾的情况下,CPU的责任就是负责这个转换,在整个32位CPU出现的年代之前，CPU都是这样转换的。 这种情况一直到32位CPU出现后也没有改变。依然是进行逻辑地址与实有地址之间的转换。不过32位数据线的CPU转换方式要特别复杂而已。 在32位CPU出现之后,寄存器能表示的逻辑地址早就是4G了,而地址总线超过了32位(除非地址总线少于逻辑能表示的数量才需要实模式那样的分段,然而32位CPU下并没有产生这样的矛盾因此可以以线性地址的直接表示方式来表示逻辑任务线性空间,然而32位CPU照样也实现了一种转换机制,这是因为它需要实现更强大的保护模式(比如多用户多任务)而不仅仅是完成寻址.

在32位CPU中，是以特殊的分段方式再加一个分页的方式,段寄存器不像实模式那样用来实际存储物理地址的线性表示,它只用来实现硬件级计算最终物理地址的一个中间存储,CPU负责这个转换，先完成逻辑地址到线性地址的转换,再完成线性地址到真实物理地址的转换
不是CPU负责这个转换，而是CPU提供了这样一种机制，和可能，具体的转换，从真实地址到逻辑地址的抽象，需要在软件上实现（比如OS上），这也就是机制和策略的关系。硬件实现提供机制，OS提供软件上可用的策略。(在机器硬件实现中是MMU和ALU的机制，在操作系统实现的是被称为存储管理的内核策略)
这些，在以后对保护模式的讲解中会详细讲到。

###### 形成任务的地址

以上，在内存中形成的“指令与数据空间”，就是任务空间。我们把计算机能寻址到的所有活动内存，能形成任务的内存空间，统称为“任务空间”。 于是，空间的表示，由线性到层次式，到了4G的时代，又重新变回了线性表示(其底下还是页表之类的层次结构)。因此，4G任务空间也有另外一种称法叫“4G线性任务空间”。 这就是说，线性表示是CPU用来形成任务的任务地址.统称为任务空间.这完全是指代转换后形成的抽象逻辑地址空间的别名。它可能就是上述转换后形成的抽象逻辑地址本质(比如32位CPU前的段式管理)，也可能是这种逻辑地址的再发展（比如4G的段页式管理） 即，为了执行程序形成任务,完成冯氏运算的本质,在内存中形成任务空间是受CPU主导的(是CPU在机器层面就直接提出的一种机制，OS再在策略上提出一个对应的“任务空间”)。

到这里为止，谈到的主要是实模下的CPU机制与任务空间。当然在保护模式下有更强大的受保护的任务空间的概念但那是以后要谈的事, 32位CPU的保护模式是在稍后出现OS时讲的,因为保护模式主要是为了促使软件系统的OS而出现的(存在这样一种趋势，硬件向软件的需求靠扰，也不是什么新鲜的事，你看图形学领域就知道了),要放在本书下一章讲解,这里只附带讲一点),

对于程序员，由于32位CPU下一个任务的线性空间表示总是4G (注意总是这个词),程序员完全不必为线性地址过少和这中间的转换而烦恼那是CPU机制和OS策略必须管的事,否则32位保护模式下的汇编工作几乎要手动驱动CPU.更别论对这种CPU上的OS的编程了。

CPU的类型系统
-------------

既然冯氏架构就是将执行指令的CPU和存放程序的内存分开的一种架构机制, CPU是PC中的总控制中心,CPU中集成了对内存的管理,在CPU的眼里一切都是内存地址,指令也是内存地址.CPU不但执行指令,还管理组织数据的事.在CPU眼里,一切都是内存地址和指令,而且这导致了冯氏模型的统一性.那么这些仅仅使机器知道如何形成任务,至于机器它能完成什么样的伤务内容呢? 最初的人们是如何使用最原始的计算机的呢？

在计算机没有出现之前,是用算盘这样的工具来计算数值的，用纸笔来记录文字信息的。人脑完成对这里面所有东西的理解。后来出现了数字计算机和文字计算机，计算机内部引入了对数值和文字的表达和处理机制，计算机能做算盘和纸笔才能做的事。这就是CPU中的指令系统和类型系统要谈到的。

然后又出现了针对这种简单计算机的编程器。**CPU是可编程（表达程序逻辑）的和可运行程序的**，它有自己的寄存器，硬连线微代码机制，，，编程器据此能完成向计算机传达“将要进行何种数据计算”，“在这个数据计算中有哪些存储在什么地方的数参与了计算”，“如何存储一段文字并显示在屏幕哪个位置”之类的事情，然后计算机来完成计算或显示它们。最初的编程模式于是出现。

图灵理论支持着硬件平台，正是类型理论支持着抽象和映射,,机器的类型系统成为最初的语言的类型系统(在编译器中被提供),进而支持着编程的展开。


###### 机器类型，抽象类型

从一种绝对的理论上来讲,0,1可以直接表示无穷和无限的信息(硬件程序员就是“痛并快乐着”地实践着这个理论的一代匠人们).机器在硬件级对字母数学之类的常用基本本信息的编码是直接内置的[20. 其实并没有内置这样的编码及编码机制,而是说对以上这些类型有直接的支持.](所谓计算机,历史上一直就是处理科学计算,信息处理的代名词,计算机最初的用途是用它来表达信息作数值计算[21. 所以历史上地,CPU内部有运算器和逻辑器.还比如协处理浮点器],PC也不例外),只是后来可以在编程层不断抽象形成新的信息而已[22. 不过再抽象,比如抽象到了WEB应用,实际上其底层仍然是IO这些计算机工作逻辑原型.],,(从很大意义上来说,计算机是一种模拟现实的工具,计算机对现实中的数据,字符,音频,视频,的模拟实现手段是"编码",这也就是大家常说的“数字化[23. 数字化就是把纯数学的数据转化成计算机内部能够表示的离散形式,所以对于数值,会有截断现象发生.]”了,如音频,视频就是编码实现的, 字符包括字母和符号,也是用ASCII码来间接表示的) 顺序 一个多字节的数据的二进制表示有二种方式,书面表示,和内存表示 比如0xABCDEF12 这个16进制数(我将它写成这种形式表示这是这个数代表的真实值的书面形式,但是如果我不知道它是哪个平台上的我就不知道它在内存中的真实表示,我也就无法知道它究竟代表哪一个具体的真实值),一般按它的内存存储表示为准而不是书面形式为准采用降序或升序的说法,比如0xABCDEF12 这个16进制数,在intel机的内存中就是升序,而按书形式就是降序,0xABCDEF12是它的书面表示(按它在内存中被存储的方式表示就是12 EF CD AB) 内存总是从”前左低”到”后右高”位按递增数值编码的字节,,那么如何把多字节数据的二进制表示存放入线性内存呢?有二种方式,一种是"bigdian(降序,把big高位放前面低位放后面就是降的趋势了)",另一种是"little dian(升序)",这二种方式是指CPU或OS的规范(intel采用降序big,这样书面表示就跟内存表示不统一了而是相反的),也即如果从左往右是从高位到低位,就是small,如果从左往右是从低位到到高位,那么就是big

###### 整型

先来介绍各种数值数据二进制在内存中表示的机制, 有原码,反码,补码这几种编码方式,整型最普遍用的是它们在内存中的补码形式（补码原码反码指在内存中的二进制表示）,即先取它的绝对值的二进制表示,再按位取反再加1，因为原码表示时,有二种重复的位组都能表0,所以,为了不致于浪费编码指标,一般都采用不产生重复的二进制的补码形式表示。 只有整型才有“有无符号”的说法,无符号数和有符号数的这个符号就指“正或负”(我们取它在现实生活中呈现正负的说法抽象,它并不是指其在二进制层面表示的符号位,但是,一个整型在现实生活中是正是负,这显然直接影响了它的二进制表示中是否有这个“符号位”)。 所以无符号数永远只能表正数(这种“正数”实际上更精确的说法就是“无符号”,而在世俗的眼光里,无符号就是默认的正数,只有负数才需要强加一个符号去表示它为负),由于只有有符号数才有正负之分,,因此有符号数就有正,0,负这三种“有符号”数,(因为整型数最终要按某种形式,比如原码,补码,反码表示成二进制),无符号数不必考虑符号位,而有符号整型数(按它的补码形式在内存中被表示)就需考虑符号位,进位分为逻辑进位和算术进位,汇编中专门为无符号数和有符号数(在程序标志器)设置了不同的进位标志,CF就表示无符号数的进位,OF就表示有符号数的进位,当溢出时就退回到最初(表值范围就是一个周期圈),,

>任何一个软件[24. 注意语言的类型与机器的类型之间的关系,语言可以在编程层面抽象机器的类型.起最终作用的仍然是作为宿主的机器类型.]都可采用与CPU表示或OS平台采用的数值格式不同的数值格式(以符合它特定的要求),比如JVM就用全部长为32的浮点型,整型等等,,,OPENGL也有专供它自己使用的数值类型(语言中可用TYPEDEF来定义各种数值类型的子集)

###### 浮点数

浮点有它的人为标准,如IEEE标准。 浮点数可以提供很强的精确度,因为它的表数据范围很大(浮点数可以有64位,因此它的表数范围和精确度都可以达到很大,决定精确度和表数范围的都是浮点数的指数部分),而且它的小数部分可以精确很多,因此可以表示相差不大或相差很大的东西(比如真实宇宙中二个靠得很近的点,或远几光年距离的二个点),而整型数就不行(但是在计算货币的时候,浮点数的舍入操作反而不如整型数来得精确, 这是因为用计算机数值来表示纯数学中的数时,浮点数在计算机内部或虚拟机内部是以二进制表示的,一种误差形式就是截断误差(除了一切现实生活中进行到的数值计算本身总会产生误差外),它会对最终数值产生某种不期料的偏离,还比如,整型数被0除和浮点数被0除的结果是不一样的,整型数除以一个0只会产生个异常,而浮点数除于0却会产生一个NaN或无穷大,解决方法是用一种ADT而非primate type来表示不能舍入的金融数据,, 如用BigDecimal包装类型,,,,所以在计算机数值时要避免大成数和小数除数, 浮点数在书面上和内存中是如何被表示和存储的呢?在书面上有二种表示方式1是用纯粹的十进制表示(但必须带有一个小数点,如123.这样的整的浮点数)2是用带有指数的形式来表示,如12.3E1,书面上其实还有一种表示,即二进制浮点数. 当然在存储上,小数点本身和指数符E是不必按实际存储的(因为它们只用于书面标示并不是一个浮点数本质内容,浮点数本质内容是“小数点的位置应该在哪”“决定这个小数点位置的指数有多大,是正还是负”从这句话可以看出,浮点数的存储表示必须要包含1指明小数点的相对位置2指明具体的指数部分,实际上1和2是统一的),指数正负是必须要被存储的,,,又有一个浮点数书面表示的规范形式,就是小数点前有一位非零的数字,,,, 在计算机和现实中,浮点数都是用二个部分来表示的,,一个是它的基数部分,,,一个是它的伸缩表示(小数点前面是个整型,后面是个近似值故有精度的概念),,比如23.45和2345都是浮点数,,它们的基数部分是2345或者0.2345,,如果是2345,那么23.45就是2345*1/100,,2345就是2345*1/1,如果是0.2345,那么23.45就是.... 由于不论基数和小数点后面的尾数部分都是最终的浮点值的表示部分,因此有几位有效位数(不要把有效位数跟尾数部分和指数部分弄混,有效位数实际上就是基数加尾数再除去小数点的那一串数字序列,单浮点数一般为6-7位,双浮点数一般为15位,超出这些的数字序列就不称为有效位数了)实际上对最终浮点值的影响是绝对不会次于指数部分的,这是因为指数部分仅仅是伸缩度的表示,改变成另外一个伸缩度,有效位数部分就会产生新的基数和尾数部分 在内存中(只有浮点数的指数形式,因此分为二部分被存储),浮点数除去小数点的数字序列是作为二进制被存储的,一般占24位,而包含指数正负的指数部分占8位(这个长度为8位就决定了浮点数的精确度和实际表数的大小范围),,因此体现在书面表示上,从左边数只有6-7位数字序列是有效位数.再长就是没有意义的. 规格化的浮点数格式主要由三部分组成,阶码(确定小数点的位置),数符(表示正负号),尾数(表示机器数字长) 对于浮点数的表示和处理是CPU直接支持的,CPU中集成对浮点数的处理单元,一般被集成一个被称为FPU的元件上协处理器,它是一个栈式的机器元件,在计算机内部,,移位就是2的一个幂,有关浮点数的处理对于计算机来说是很快的,

###### 字符

虽然都是多字节表一个编码体，但汉字的编码与unicode是毫无关系的。没有对应和共用关系，根本是两套独立编码，这不像ASCII和欧洲各国对ascii的扩展（它们共用某区断的编码）要注意平台字符类型，语言库抽象字符类型与CPU原生字符等之间的区别，这根本上是因为软件在平台，语言，库，应用一条线上的抽象同质性。

对于字符,包括基本字符和复合字符(不是字符串,比如'abcd'实际是一个四字节字符而不是一个字符串) 记住,,有多字节字符,就是所谓的unicode宽字符,有zh-cn-utf,gbk-utf等,也有utf8,utf16等在软件中,宽节符常被用来支持软件的国际化internationalization和本土化localization. 由于计算机系统都用数值来编码字符,,因此它们在计算机内部的实现形式通常是int值,,,存在不同的标准,比如ansi,unicode,各个平台也不尽相同,因此会带来不同的兼容问题,在写源程时要注意这种兼容性,,在可执行程序移植到不同平台时也得注意.. 原先对字符编码的标准有美国的ASCII和西欧的ISO,中国的GB和BIG5等,当然还有其它国家的 unicode组织和iso的ucs(统一字符集uni character set)小组都是为了统一字符的一致努力而存在的,,当它们走到一起的时候,他们相互妥协并整合各自的成果推出了一些东东 unicode原来用2字节编码65535个字符(注意,这只是对字符的编码,并非实际的在计算机内部表示并存储字符(因此,它跟我们在“硬件的指令系统和类型系统”中讲到的字符类型问题不一样),由于2的16次方为65535,因此它只能在概念上抽象对应65535个字符), 然而,光就汉字(包括康希字典中的繁体字)来说,65535个表示就显得少了点,更别说表示其它非拼音语言的字符了 ucs原来用四字字编码字符,, 后来他们共同制定出来一个“统汉字” 即把CJK(chinese,janpanese,krean这些都是汉字的变体)称为统汉字unihan(han就是汉字的意思,uni就是统一的意思),,把它们当中的一些字符进行整合,简化,删除,硬是把三国汉字弄到了65536个之内,即U+0000到U+FFFF 注意这65535还是utf16的基本代码级别(code plane,想象大型油轮的一等创,二等创,,,,就是VS编译时常出现的C4819号警告中的那个code page),还有超出这些分(即U+10000开始的)的就用其它级别表示,UTF16有1-17个级别,其它16个级别称为辅助级别 这些辅助字符是用先前65535个位中其中2048个(D800-DBFF1024个和DC00-DFFF1024个)没用到的空闲位的其中二个组合而成的,并把他们的编码统一到U+10000开始的地方作为编码点code point 关于u这种转义符可以直接出现在Java源程序中,并且可以脱离单引号(char)和双引号(string)在源程序文本中存在,当然也可放置其中(如果不放置其中就是普通的文本,放入单或双引号内就是作为常量串) 转义字符就是不作为普通字符(可打引,可显示)的控制字符(可是本质上都是字符因此一同编码),它们也跟普通字符一样被unicode编码(因此可作为书写源程序清单中出现的普通文本字符---本来整个就是UNICODE文本文档嘛,,也可以作为变量标识名---本来就是字母字符和数字字符和下划线字符的组合嘛,况且JAVA还支持unicode变量呢). 并弄出了诸如utf8,utf16(转换机制,8,16表位数),,ucs2,ucs4(存储机制,2,4表字节数)这样的东东 utf(即统一字符转换格式)是一种转换机制,把非统一字符转换成统一字符的机制(包括一切字符),有utf8,utf16,这里的8,16是bit,,由于这里不涉及到存储,这里的bit只是表示“用多少bit就可以表示一个字符的统一字符码”,比如utf8就是用8位就可以编码达成,而不是表示一个经过utf8转换的字符实际只占8位,,实际上,经过utf8编码的字可能有三个字节长(最小2-最长4个字节,即一定要满足ucs2,ucs4) U+0x0000到U+0xFFFF的格式是什么意思呢(U+就表示unicode代码点的意思) 0x0000到0xFFFF是编码区位(即在unicode码表中的区位,有2字节,因此有65535个位置供原始字符用,称为代码点code point),而U就是关于一个原始字的它的utf8格式,,它们结合起来就是该原始字的统一编码的存储形式

>一门语言的字符逻辑涉及到数据结构与IO,所以是一门语言非常重要的部分. 在C语言的眼光中,字符的本质是int,字符串的本质是数组,或指针 字符串是各大语言要考虑的对象,首先各个平台上字符串逻辑都不一样(有的用四个字节内存,有的二个),,即使同一平台不同的语言实现也不相同(你看C在字符串后加一个终止符),,而且,也有关于字符串处理超大逻辑(正规表达式),甚至于一门语言本身的词法处理,,,也涉及到自动机(当然,并非正规式)和正规式(自动机对正规式产生的正规集进行处理)? 而且,在WEB开发上,字符串跟I/O又有关,是WEB开发的重中之重..

###### 布尔编辑

下面说一下布尔运算符，早期的计算机不但是个数值计算器，而且是个逻辑推断器，因此有布尔代数元素的出现，布尔运算符即逻辑运算符,(程序语言中还有关系运算符,算术运算符,位操作符等,,然而这里的关系运算符却不是《关系代数》中的运算符,关系代数是一个离数中的代数系统,它自有它封闭而自成系统的数据集合和运算符,《布尔代数》研究0和1的运算,比如累加器的实现等等) 关系运算符就是比较二个或多个数之间大小,是否相等等关系的运算符 位操作符跟逻辑运算符比较类似(不一定只有二个运算子参与逻辑运算或位运算,而且它们的运算规则也比较类似,而且运算符也比较类似逻辑是双体号而位操作是单体号),它们之间明显的区别在:逻辑是命题相关的,因此跟短路规则有关(这是说在if这样的条件句中),而位操作符跟位操作有关,因此不进行短路规则的判断 位移全1为1，，与常被用来清除，所以也可以用于保留提取某字节中的某些位，见1为1，一切以"1"为准来记忆 逻辑与即逻辑乘,见0为0,全1为1, 逻辑或即逻辑加,见1为1,全0为0, 还有逻辑和位操作中的XOR,也即只有运算子不同时才能取到1,相同时为0 位运算主要是利用屏蔽技术取得整型数(的二进制表示)的某些特定位,运算规则跟逻辑运算是一致的 因此在位屏蔽中,用1与“与”的组合可判断某位是0还是1,因此在位屏蔽中,用0与“或”的组合可判断某位是0还是1 位移和位段,, 移位有单向和循环移位,

在C++中的布尔可以是一切整型值,这其中为0即false,非0即true,然而在JAVA中只有二种值true或false 比如C++中的指针,由于它是一个整型值(可能是0或不是0),我们可以直接用一个表示非的叹号置于一指针前,然后用整个的取值作为if的算式 为什么布尔可以有这么多值或者只有二种值呢,,boolean只是int的typedef 子集,一般用0表假用1表真,

###### 小结

但是还是有一些问题没有解决，试问：算盘能表达并处理“数量为1的一头猪从城东跑到跑西”这样的“跑”概念吗？纸笔不能（它能表达“猪”，“1”，“城东”，“城西”这样的文字并写在纸上），算盘不能（它能处理1头猪与1头猪相加数量为2头猪）。

这是因为**它们不能表达抽象**（比如除了文字表达，文字显示，数值表示，数值相加之外的任何其它信息）。只有人脑能做这样的想象(将不同质的一个信息映射为另一层面并形象化它们)。

所以。如果计算机只是数值处理工具文字处理工具，且编程器只能处理数值和文字，那么它们就是另外一种更大更快的算盘和纸笔而已，它依然不能表达抽象。

>(在这里，简单计算机相当于平台，编程器相当于语言设施，编程器充当平台与问题之间的连接器，它的职能在于向平台表达一个问题，并表达如何处理它，这就相当于现代高级语言编译器和软件平台比如OS，只不过后二者层次要抽象得多)

等到出现OS后，OS提供了更丰富的类型和抽象，语言可供操作的数据多了，通过算法实现和封装，它还可以发展更多的抽象,从这里开始会慢慢谈到编程,,不过这是后话了。


CPU的指令系统与裸机会编
-------------

“在CPU眼里,一切都是内存地址和指令”,是什么本质,它带来了什么意义 想想,体现到对这种机器的开发工作上,它带给开发者什么样的编程体验和要求? (这种指令跳转上的顺序性,天然地对应着它“存储器存储顺序指令集,ＣＰＵ执行顺序指令集”这种简单的工作模式,这就对编码工作提供了无比便利的条件,使得冯氏下的编码工作变得无比统一).（况且，统一编码的任何已由BIOS完成了）

所以,在对冯氏系统的开发中,就形成了一种组织指令,与组织指令用到的数据(指令数据在内存中的位置,或编码了的数值和字符)的方式.这正是我们今天看到的冯氏机复杂外表下最真实的内在.

这样一来,我们编程也成了书写指令和指定供指令操作用的地址,指令内含内存地址为操作码,.冯氏机以及它提出的“指令控制存储并串行顺序执行”的理念,这些都深克影响了我们这个时代的编程工作.这也就是汇编与机器语言的方式了(未经高级语言语法调整的顺序指令组成的程序与编程工作).

冯氏机的指令执行(包括对数据的定义与传送)是一种确定的,顺序的结构,知道这个有什么用呢?知道这个有助于我们理解冯氏系统的串行本质,而这种串行本质,是学习其它更抽象的东西的前提,比如指令到底是怎么发挥作用的.

###### 存在多种会编和会编环境

比如汇编著由那些语言要素组成?汇编编程是一种什么样的本质?首先理解内存地址是什么,程序如何在OS中执行这样的软件的系统逻辑是如何在初级的冯氏运行本质上包装实现出来的基础.

在将下来对CPU的类型系统和指令系统的讲解中,并不打算涉及到特别复杂的情况,因为我们选取的是80286之前的情形，即实模下不存在软件系统的对裸机的编程，指令作为唯一意义上的软件，存在于机器的执行路径中.实模式下裸机和保护模式下的裸机,因为这二种环境下,裸机得到的功能和所处的意义范畴是完全不一样的(CPU为了产生保护模式增加的部件逻辑跟实模式比起来可以说是一个不小的改变),而在机器的实模式下和保护模式下,都存在软件系统,所以汇编又大概分对实模式下的软件系统的编程和对保护模式下软件系统的编程. 而其实,实模式下对裸机的编程是最首先被应该讲解的,因为它一方面涉及到对初级的计算机硬件的了解(尤其是功能方面对应着编程的那些东西),一方面涉及到对初步的汇编语言语素的了解(这就开始涉及到了编程).而所有其它的组合,是更高级的东西. 而且,因为我们设想本书的读者是看到1.3章节的内容再看到本节的初学者,所以我们还是一步一步来讲解吧

类型 这里讲不讲

pure汇编,裸机汇编 讲

保护模式汇编 不

OS上的汇编 不

所以作为对机器语言一一对应体的汇编语言,它也是一种顺序语言,它的流程控制只能是对指令选择与跳转层面上的一种抽象,虽然它也可模拟高级语言的子程序等概念,但它是基于指令选择的,不带有语法语义的,高级语言在意义上也抽象了结构与流程,然而在做法上,它是属于高级语言的,带有语法的属性的,至少它不是基于指令的而是基于语法的

注意:在机器的范畴,我们将尽量少用程序的概念,而改用指令集的概念 机器的观点永远是机械的寻址和执行指令,实际上在没有高级编程语言理论之前,远远还没有程序的概念,因此不能说指令集是程序,更不能说指令是语句,甚至语句与代码的概念是严格不一样的.也不能说地址是个变量,地址里面的东西更不能称为数据类型,CPU能直接执行和认识的只是由0,1表达的指令和编码的地址以及各种机器级能表示的基本数值和字符,只是后来以人的眼光来看可以无穷地把0,1编码成其它各种逻辑(编程级的代码和数据),而在高级语言中,进一步地,如何在内存中组织数据又发展出了数据结构,用底层的观点加数据结构的观点来解释现实事物的解法就形成了算法,不过在汇编语言级别,这些都不是机器能直接理解的
读完了以上这段,请确保你看到了“顺序”与“串行”二字.

###### 寻址和跳转

因为我们是拿80286的实模式来讨论的,所以我们需要知道它里面的指令的意义.下面简单列出几条.

指令跳转这样的逻辑在高级语言中被进一步抽象为三种流程控制,甚至C语言中的信号量,C++的异常这样的逻辑.当然,我们分析的过程是逆向的,遵循的是一种反工程的路径,因为我们这本书是谈高级编程的,所有的话题都是服务于高级语言,所以关于汇编的讨论也是一样.

指令的向前跳转和回退(backtrace) 抽象指令：控制结构

###### 对裸机的会编编程(功能调用性编程)

裸机是可以执行程序(bios)的, BIOS的功能是为了人们控制计算机的硬件接口，所以是可以被编程的（IO子系统的指令都被硬连级和微代码实现在这里，成为裸机会编程序逻辑的来源。IO指令,指一些包含在BIOS中的,计算机的基本输入输出系统. 中断处理往往被做在外设的硬连级的微代码中。(它是硬件上固化的,而各种驱动程序实现的,都是软件上的)）,因为计算机硬件上的功能就是BIOS的集合,所有计算机在软件上的功能,包括OS抽象出来的,语言和编程层所抽象出来的全部后来逻辑,都是由BIOS来的.故谈这个是十分必要的. 

>bios只是IO设备的功能，不能代表PC的整个硬件功能

什么是BIOS呢?设想一台没有安装任何软件的刚买来的计算机,从通电开始,CPU被复位,进入实模式,最先进入到的是BIOS,BIOS里有系统里安装的各种硬件功能的全部例程,它初始化它们,然后当发现,比如,硬盘的开始处有OS的引导记录,CPU才开始把执行权,从BIOS移到OS(之后的内容,至少不属于我们现在讨论的内容,我们前面才刚谈到实模式下的CPU和内存的关系而已,让我们保持一惯的传统,假装我们对那些东西都一无所知).所以,BIOS里,一定有计算机最初的软件逻辑的载体.它们掌握控制裸机硬件层的那些东西.比如,CPU的驱动,如何进入保护模式的逻辑,IO硬件的驱动. 不管这么多,就让我们从学习汇编的方式来开始学习对裸机的BIOS编程吧. 汇编,是用来取代机器语言的,但是因为它们做到了在本质上保持了机器语言的基本原形没变(指令的确定性及顺序性,以及机器编程的本质在于指令选择),所以讨论(比如我们这里讨论对裸机的编程)时,经常拿它来代替机器语言.

汇编是每一种CPU每一种机器的专用语言,我们今天用的i386架构的CPU,里面的每条指令在汇编语言里都有表示.

学汇编(包括反汇编)其实就二个东西,只要搞清数据是如何寻址的,和指令是如何跳转的(机器编程的本质在于指令选择),和数据在什么地方发生了传送(会编程序唯一的上下文就是堆栈，，这些在中断和硬件级的执行路径中会谈到),你就明白了一段汇编码在汇编级的逻辑.说白点,你学会了汇编语言.当然我们的讲解也会侧重在这二个方面进行.

还有什么没做？我们到哪了？
--------------

我们现在还没有软件系统，只能用它做针孔打字机。

我们的计算机内部运行着二种程序，硬件规程（规定的程序），它们不可改变，和会编指令来调用它们的逻辑(这是唯一的用户程序)。这是可以改变的，是我们要谈的编程。

我们还没谈到与外设的交互。甚至代码出错了在硬件级是不是存在一种挽回机制（出错的上下文能不能恢复），如果有，这种挽回处理程序是不是也在BIOS中，而且，CPU是如何转入的。在处理完后，如何恢复继续处理。

而且，在用户程序级，一切仅是指令，出错了由程序员自己管理，而且，BIOS不提供任何更多的东西，甚至更多管理机制以方便会编程序员的工作展开。


可编程机器：对子系统和中断的支持
=============

前面说到，CPU是可编程的，cpu isjust a instruction executiver(串行表示但可执行时跳转的指令序列) while refering memeroy（实模式下的分段地址）,这些只指出了它与内存协调能正常工作的一面，但是，当出了问题怎么办？（当前指令不能正确执行需要跳转到某段存在某处，可能在BIOS中的处理规程，中被处理，处理后如何跳回），而且，前面说到的打字机是如何向CPU输入程序的，我们甚至都没有说明它是如何被接入PC的，当需要与外部交互（应是一段BIOS规程代表打字机的功能，然后CPU利用PC的某种机制与它交互。与出了问题时的处理程序一样，CPU在进入工作与完成工作后跳入跳出。）怎么办？？

>>即，CPU不光不光完全自己的事(我们后来知道这件事是任务),还要使用某种手段,比如处理它与其它子系统,比如带有IO性质的子系统（统称为IO子系统）的交互,而且，异常也提供了出错的处理，是cpu设计时除了正常指令支持（有常体系）之外的另外一个体系（异常体系），实际上，都是内部体系的组成块，正异常是正常的两个方面。

这样,cpu利用某种消息机制与外设交互，将外设规程和异常规程也弄为可编程的(将它们在BIOS中的规程与CPU的正常指令统一编址执行)。弄成一个功能丰富和完善的PC。。

这就是中断，这就需要PC在硬件级提供中断。CPU有二概中断针脚（所以**中断是硬件PC的机制,,与CPU加内存的那个体系是并列的**,,PC内部的PIC也是可编程的中断控制器）,用来接受中断，这往往来自于CPU外部打断CPU当前执行的指令序列需要立即进入CPU内部被实时处理的那些信息的需要。(将他们的例程中断入CPU加内存形成的那个编程系统)

中断在OS内核中被后来发展为抽象中断系统与抽象CPU一起的抽象任务系统构成虚拟PC，，这些都是软件上的后话了。





机器级的调试和对异常的支持
-------------

gc,自动内存管理，exception,opt in自动错误处理，不在于错误与异常的区别，，而在于语言缺省提供支持的区别

错误代码这种方法要求程序员去完成人类不擅长的工作--任何时候的一致性和完整性，并且系统环境没有给你任何帮助。异常(Exception)将使这一切变得容易很多。 　　 是Opt Out而不是Opt In 　　错误代码和异常最重要的不同在于对做正确的事情的要求不一样。错误代码使用的是Opt in，如果代码中对错误没有做明确的处理，那么这个错误就会被忽略。 　　而异常(Exceptions)使用的是Opt Out模型。在默认情况下，运行时(runtime)会根据这些异常(exceptions)做正确的处理。 　　这个区别对编写的代码有着很重要的影响。因为运行时(Runtime)能对问题进行常规的处理，所以程序员就可以将精力放在那些需要特

whatis the differ between ordinary 错误处理 and 异常捕获


###### 中断

中断是硬件级的消息,中断和异常是CPU直接相关的东西(CPU有二跟中断引脚,中断处理功能是CPU的能力和逻辑),,,很多编译器和语言提供了异常处理机制,Windows更是实现了一个SEH,,但是,这些都是抽象了CPU的这方面的逻辑..
中断中的硬件中断是真正意义上的中断,把它称为中断是为了跟异常区别开来,二者都指CPU[1. 有时，OS和用户也可以扩展中断，OS就是一系列的软中断作为基础设施而提供服务和API的。]

CPU对于执行程序的本能是天生的,它以一种处理加工数据的方式(内存修改器的工作本质)来完成它的工作,而且,它还负责将这种工作做到无误（有时也是为了加进用户的干预）,这就是机器级的调试.

机器系统的中断也是有常而不是异常，是有限的
对有常编程，对异常，能想象到的给它一个except,不能想象的，也就没办法处理了，因为有常有度，而异常无度也 


在设计开发一种”系统”时(比如PC系统本身),开发工作不可能直接在这个未实现的平台上进行.因为一没有OS [2. OS也是一种”低级”开发平台,也是一种必要的运行平台,前面谈到在它上面运行的软件都是native的],二,因为没有OS,也就没有编译器[3. 不会告诉我你想用汇编吧?都什么年代了,还谈到开发就动不动想到汇编啊?(除了硬件编程,和调试领域,需要用到它之外,其实对于高级语言的程序员,对于会编,它们接确得最多的地方,大约就只有调试的时候了)],当然也更没有像.net,jvm这样的高阶开发平台可用.所以开发往往是在几个平台之间交叉的.借助其它平台的强大的编程支持.当工作完成之后,只需做移殖的工作即可. 一般的步骤是先在另外一个平台上实现一个软件的仿真器来模拟目标平台(当然也有硬件的开发板),这种软件上的虚拟机是对目标”机”的模拟[4. 虚拟机是对CPU的模拟(还有模拟中断机制和IO),,,一般提到硬件的“机”就是指冯氏的构架],,运行在这个平台上但对虚拟机编程的编译器叫交叉编译器.在虚拟机设计完成并实现之后,这个编译环境也要移殖到虚拟机上(此时称它被实现到目标硬件平台上)[5. ,,这里面的工作是:用这门语言产生关于这门语言在新硬件环境下的编译器就可以了.如果这种语言是自实现的.] 然后,操作系统这样的东西就可以在这个基础上开始设计并实现了..但用仿真器方式来验证此机器,和提供一个编译器,这是首先要做的事情.. 当然,仿真器只是模拟了硬件架构环境[6. 对于硬件平台架构,CPU是首先要谈的东西..Intel的构架有专门一本书来讲解.汇编语言就是CPU的汇编语言,不同的机器有不同的指令集..因此有不同的汇编语言,这就是移殖问题最初产生的地方..],有一些高级的虚拟机可以同时模拟硬件架构和OS. 如果你玩过软件的虚拟机就知道了,,市面上存在很多虚拟机..但这里的虚拟机不是平台,而是软件,,跟我们谈到的jvm,.net是二回事.我们谈到的jvm,.net是开发平台..而且是高级开发平台,而不是实现平台.

同样为了开发(开发一个系统,就是同时开发硬件,OS,和上面的一系列软件,这样的一种完整系统)的需要,,调试器也是需要的,一般的IDE都有调试器,调试逻辑来源于CPU逻辑,intel中有断点中断处理例程,,中断一般来源硬件动作,,但也可在源程序中人为地给CPU下一个软件中断,这就是int指,interrput的前三个字母,int 3这样的指令让CPU产生一个陷阱状态,让机器进入调试状态,此时CPU并不正常执行程序,,而是一步一步地执行程序.. 调试器分硬件级的和软件级的,但都是为了让开发者或机器调试者研究程序在机器内部二进制级别的执行程序,,调试器一般向你显示CPU寄存器状态,符号信息,内存上下文等等..

CPU在执行程序时,会为程序保留一个当时的CPU环境,执行上下文,CPU要继续执行,只需要获取到这些内容,就可以保持与下面的指令的逻辑完备.

执行上下文即为机器级的调试提供了可能.

>反会编与反工程 汇编在这个软工当行的年代更多是一种反工程的手段。

要注意的是：由于工程和反工程是一对互逆物，所以其实反工程和工程都是统一的，反工程其实也是工程，不理解软件工程，也就理解不了反工程的意义和动机所在，也就缺少了正确反工程的重要手段(我们必须用工程的眼光去看懂会编码，猜测它背后的C语义，确定其最初工程目的)。 调试提供了一种以人力可控性地查看源码级和机器码级逻辑(有时不是一个软件进行反会编，而是对一份数据进行反会编)的方法，有时，在文档或源码不可得的情况下，它是唯一获取软件内部信息的手段，有时，在排错或研究的时候，也大有用场，它是锻练程序能力极有效的途径。

###### 异常

异常,全称为“进程的异常”,当然在硬件级也有CPU的异常.

故，也存在OS级的中断的说法。]对影响它原来指令流程的意外干预过程.(CPU对这二者都提供了处理例程,但硬件中断处理例程,是内置在硬件级的,比如CPU中,或软件上属于硬件逻辑那部分中的,比如设备驱动程序中).但是中断是硬件级的,是来自外部的,异常是来自CPU内部的指令执行过程中的一个出错(有时,这种异常是故意的,所以不能称为错误,比如缺页中断),,是来自指令执行过程中的(所以,所谓的软中断指令其实也是异常).软中断,是软件上“机器功能集”的实现支撑,比如,用软中断实现的“system calls”
而发生中断或异常时,二者都是靠CPU的跳转指令来完成跳转到相应的处理例程的,,这是CPU直接执行指令的结果[7. Ruby甚至鼓励用中断和异常来代替正常跳转,这是直接用CPU的指令的结果,编译器控制不好会造成很多隐患],机器级的跳转指令是程序语言实现它的控制流的一个重要方面.

机器级的执行路径：指令的运行环境
-------------

任何一个系统(无论它是硬件还是软件的)都必须给运行它上面的程序提供一个运行支持逻辑(一个不能运行程序的系统有什么用呢?OS core的任务之一就是给用户级的程序执行提供一个路径,而这由提供进程和任务空间开始,当然,任务空间和进程不是直接的执行路径所指,而是执行路径上的大逻辑单位.某个活动的进程内部,其内存在执行路径), 在OS层面来谈就是c call stack执行路径.在CPU和机器层面是目标平台的指令与数据,进入到CPU和机器的执行路径.
一个用汇编写成的程序,是一组逻辑上有机的指令集,活动的程序就表现为存在于执行路径中(这时的执行路径只是一段电器化的堆栈)的指令和数据(或称数据与代码).

指令与数据,数据与代码处在不同的说法层面,而我们人称之为数据和代码,依据是当它没有运行存在一个静态asm源文件中时(我们称呼这个源码整体为代码,称呼那些load,assign后的数据为数据),其实所谓代码,从机器的执行眼光来看,也是某种形式的栈式数据,它只看到活动的数据存在于它的执行路径中(所以指令一律都是数据,也即代码即数据) 在稍后的章节中,我们会看到数据系统与代码系统新的含义(OS引入了软件层的c callstack执行路径[8. 因为一般OS都由C语言写成],高级语言引入了类型机制,编译后端也参与程序运行,引入了运行时,这些都改变了数据与代码的含义)

我们把从执行路径中看到的栈式东西看成是代码与数据的定义的依据,即,只要出现在其中的或者是数据或者是代码,(一概而论之,栈式数据)
当然，执行路径不只包括这些，比如，中断如何保护执行，这其实也是执行路径的一部分。

我们注意到指令是被串行顺序[9. 任何时候,机器只有一个活动的执行上下文存在CPU中,包括当时的活动指令及修改的存储器------我们将它称为一个执行路径,在稍后的章节中将看到进程的概念,所以,冯氏机本质上不是一个并行系统]执行的,

我们现在的机器一般有二种,堆栈原理运行程序(执行时即很深的堆栈嵌套)的和reg式的.

**现今的机器一般都属于堆栈原理**,在执行路径中存在极其复杂的nested stack,这些stack中,有一个全局的stack(即exe体中堆栈段开始的地方,用来指示这个堆栈段)和大量的其它的子stack(用来指示每个过程所用的子堆栈开始的地方,也叫堆帧),故存在二大基址和偏移定位系统,一是全局基址和全局偏移,一是本地基址和本地偏移,这二套机制各自完成对堆栈内数据的执行时定位.

如果机器是堆栈机(采用内存stack方式的运行逻辑),那么它就是用内存来作为主要运行场所的机器,JVM速度很慢,但是很耗内存,从这点就可以看出来了(因为它的机器中没有软件摸拟的Reg,,为了跨平台,jvm根本不打算将x86的Reg机制引入,而我们的x86平台是硬件的reg,所以称为本地平台,硬件的reg总比软件模拟的快)

机器如果是寄存器机,那么主要用寄存器来执行语句逻辑,指令逻辑,完成数据的传送(语句即指令加数据,为什么任何一个逻辑正确的可执行文件为什么CPU能执行它并产生结果呢,这是因为一切pe逻辑都可反汇编译成指令加数据的语句,它能被执行,因为它同时包含了代码加数据,CPU不能执行纯Data或纯Text),,因为寄存器是CPU的而堆栈是内存的,所以reg机明显比单纯利用内存的Stack机快,但是寄存器器数量和容量有限(比如递归不好做),所以针对这类机器设计的单个指令代码长度一般不长,,在一些方面是比不上Stack机的 首先,对于x86平台,是如何执行函数逻辑(比如反汇编的一段C语言的函数的附近得到的一段汇编语句)的呢,,通过探索这个过程分析那些汇编逻辑(其实就是编译器产生的平台逻辑,机器码嘛),我们可以发现这个平台的运行时底层信息 首先,PE载体逻辑内有一段堆栈段,被映射到内存(载入器和重定位器会完成这个工作)后形成一个堆栈区,寄存器此时高速活动,它的一个活动记录中,必定保存有栈基栈顶的一个指针(此时它们重合) 堆栈的基础概念要掌握,它是一段从高地向低地生长的空间,而且是活动空间,因为栈顶(指示当前出栈入栈位置的指示,它存在sp reg内,永远只拥有一个是‘’当前“的值,减它就是在低地址更低所以是为堆栈腾生长空间,加它是让低地址往高地不低一点,堆栈空间会变小)会因为频繁的出入栈动作而变动.这种变动性使得我们掌握堆栈的方式(求某一个成员在此活动堆栈空间的位置)只能用简单的'bp"+-该成员对应bp的偏移,的方式来指定了,而栈顶的偏移永远是sp-bp 堆栈和堆栈帧 把栈想象成一个智能水桶,,当空时,,它要盛水,就要上端开口,下端关 当使用这桶水时,下端开,上端不需要再灌水了 这就是说,1它是二端开口的,但读存操作只能通过一端进行,这二端一个是高地址,一个是内存低地,一般是将高地作为栈顶和读写源 2,所谓FIFO,这里的FIRST或LAST,是相对I或O一端的那些出入数据来说的 3,栈这种内存块是动态扩展生成的,,,每个函数都在它自己的栈作为EXE进程栈的一部分,,,,被称为一个栈帧

总结
-------------

学了这么多,让我们来总结一下:

我们注意到冯氏机主要处理数据和代码,而指令是控制数据(CPU是控制存储的)的,即冯氏系统在硬件上,是一种数据的内存修改器，这使得我们后来的编程工作的抽象焦点在于数据和语句.这是冯氏模型对编程工作最大的影响.

>这说明冯氏模型一开始就被设计成为非并行计算机[10. 这也是向量计算机产生的原因],因此在后来编程中,要实现并发逻辑需要从软件上和设计上去突破.

硬件本身,是有着功能限制的,打破这种限制.可以造出向量计算机这样的硬件方案,其实还可以去软件上去扩展.后者导致了编程(所以,为了扩展PC体系本身的功能,软件开发也是有必要出现的).最初的编程当然是用指令控制机器本身,或用指令完成用户任务.但随着编程的不断发展,继而导致出OS这样的东西,和高级有语言这样的东西.

我们还注意到冯氏上的执行机制既然只是CPU加内存运转的结构,而一切软件逻辑都来源于此,这体现在一门具体的编程语言中,其源程序往往是面向运行期的,以完成到应用的映射,换言之,**源程序本身根本不代表设计**. 它们大部分只是做了映射平台的工作，真正的对应用和业务的描述逻辑很少很少。

语言表达的内容是逻纯逻辑的(其本质是编译原理)，并无实质所指，平台逻辑才是实质（其本质是图灵机），语言大都是运行期逻辑，只是平台逻辑被语言封装变成有实质内容的平台逻辑表达语言（系统语言）。即，我们要弄清语言和平台在功能上的本质属性。

其它(我们还未遇到的情况)..这些问题,都要靠软件层面来解决.
因为我们看了一下这种CPU支持下的内存寻址机制.在学习汇编程序设计之前,这有助于让我们澄清汇编的一些本质东西.

明白了以上这三个概念,让我们再来看下面的章节,实模式[11. 为什么实模式呢?因为保护模式是生来就为高级的OS设置的.对于裸机,它是强大过了头的.只有谈到32位汇编谈到它,才是有意义的,而对谈裸机的汇编编程,实模式是最合适的.]下的汇编编程(即尚未出现软件,尚未出现OS的对裸机的编程)

