其它OS子系统的职能(1) : 图形系统
=============

注意,我们这里并不谈GPU. 当我们开始讨论图形学时,又一次回到了计算机本质这个话题.CPU和GPU是什么呢?

>最初的计算机计算能力有限，所以仅设置一个计算单元即CPU，当需要超强多媒体功能时，CPU要么是加上MMX指令，要么是再在PC体系中接入一个CPU，这就是GPU的雏形

计算机是由数学危机导致产生的,它的本质是基于数学原理的,它的结构也是离散的,它的CPU也是处理数学元素本质的(全加器.累加器,半加器,浮点器),所以,它解决问题的时候,比如图形学的问题时,往往最根本上,是用数学手段.

**整个计算机,实质上是一台数学机器.(它原来只是数学和数学家的工具),本来就被用于数值处理.它用解决数学的方法(算法和离散类型),,来解决计算机能解决的一切问题.**

计算机图形学领域,就是一个处处充斥着数学器息的领域.






Graphic与gui
-------------

PC中,除了CPU和主存,其它的周边设备,都是通过IO跟CPU和主存发生联系,受管理的,所以又称为IO设备(当然,总线这样的东西,是横在这二大体系中间的,但一般不独立把它们拿出来的讨论,因为它们仅仅是“电线”[1. 仲裁器跟原子操作有关,它假设经过仲裁的指令,是“一下子完成”的,中间不可能有中断发生.].) 在前面,我们讲到了CPU和内存作为任务部件的作用,这就是PC的主要系统.我们作一个区分,任务,IO,是系统,,主系统,(filesystem+memery)DB,(网卡)NetWork,(图形卡)GUI是系统开发 中的子系统subsytems,windows内核的组织也如此 系统编程,其实是你打开任何一本稍微完整的关于程序设计语言的书所看到的目录列表中的条目,无论它是java的,还是c++的,这些条目往往包括,(我们以java《java2从入门到精通》为例,java实际上有二部分desktop edition和enterprise edition,我这里说的是关乎系统编程的desktop editon),比如,awt GUI,network,exception,corrcurrent,io,jdbc,等等等等,这些从来都是一门系统编程语言所涉及到的主体东西.j2ee从来都是建立在j2se之上的.以它为基础的.这就是说,j2ee只完成一个框架性作用.它的业务逻辑,可能正来自于j2se,因为j2se才是jdk的主体和基础.j2ee并不能拿来独立存在.或被使用. 作为多面手的OS内核,它(除了控制机器)的另一个意义,在一定意义上,就是为了提供机制支持“用户程序”的模型,所以,除了任务,IO这些被作为管理机器的功能不需要被用户程序直接涉及外(只有系统程序才用到直接从system call上着手,自助管理IO,内存的使用,比如内存池,标准意义上的应用程序和用户程序只处理界面,网络,DB上的模型就够了)历史上,TCP作为联网程序支持模型,被集入内核,但为什么TCP/IP跟GUI,它们对于内核来说,处在同一个层次上(都是高于任务跟IO的程序模型),但为什么一般内核只集成TCP/IP,但没有集中GUI呢?
关于界面的部分请从本书第三部分《learning graphic programming》获取更多信息, 这里将完善关于网络,任务,ＩＯ(数据库)的


basic graphics hardware和computer graphics原理
-------------

Graphic baias(基本显卡系统中的颜色显示系统,光栅化系统,与显存缓冲系统) 颜色系统与颜色硬件

从物理[2. 物理是研究力热光电的学科.力,光跟计算机图形学密切相关]光学的角度来说,颜色是一种光的属性,而光是人类的眼睛能够感知到的,一定频率的“波”,或“能量”.光的波动性和能量性理论能解释很多东西并用在计算机图形学上(比如光的能量性可用于稍后讨论的辐射度),但现在为止,我们仅研究光的色彩(它属于光的波动性解释,一束光的各种颜色所代表的频率,就处在这种光波的某频道上).它形成了现实中我们能看到的图形的色彩(我们能看到物体的颜色,是因为带有这种颜色属性的光,从物体表面以可识别的频率进入我们的眼睛).并用于计算机图形学.这就是显示器.它可以用发光的形式来表达色彩.进而显示屏上的图形.

显示器(以CRT来说),就是PC上能够通过发射光的手段来产生人眼可见颜色的硬件.它接收来自显卡上的控制信息,将这种数字信息投射到屏幕上,于是人眼可以看到(这就是说,CRT自主可以产生光,显卡只是对产生什么样的光起一个控制作用,它独立于显卡).

与之类似的,是其它一些图形硬件,比如PC上的摄像头(注意,我们这里不谈到照像机之类的东西,比如我们假定这个摄像头为USB的[3. 我们不想把它与3d硬件中的摄像机和摄像空间流水线之类的概念混淆]),它能捕获来自现实的光的信息,数字化到显卡,这个动作称为采样.当被显示器通过发它自己的光显示出来的时候(实际上是显示了数字化后的信息,模拟了现实中那些光的颜色),这里面经过了一个数模转换.

因为显示器的光并非纯自然的光,所以它并不能反映真实的颜色.所以会有一个gamma较正的技术.所以出现了对各种颜色进行规范的手段.

一般有NTSC这样的颜色系统.

在PC上,如何在编程层面得到颜色呢?比如得到一个调色板,这就是softer host

显卡 最初的显卡并不是GPU,而只是显存加光栅器组成的板上卡,vga IBMPC配备了最初的一块显卡. 光栅器与光栅化

computer graphics hardware!= graphics render
渲染是软件的概念,硬件并不能完成一个“渲染”,它只是处理(提供软件上的runtime可用的机制),比如显示器回放颜色,显存存储颜色信息(后来的3d显卡可以放顶点和深度),光栅器在CRT上作scan – line,把显存内容铺到屏幕上,这其中任何一者或它们全部,都不构成“渲染”,所以我们只能说,在概念上存在一个“渲染”,它代表“用户提供作图信息,”这样一整个过程(显然,这个过程不是光凭硬件处理意义上的东西能全部包括的)

图形本来就该硬件加速，说硬件加速的图形实是在多此一举

(当然你要说硬件级有一个渲染,或渲染管线的概念我也不加反驳,我主要是为了方便整书在以后涉及到渲染时作一个措词上的铺垫付).

光栅化处在渲染的后端,硬件只是机制,软件才是策略上的渲染 Pipeline是render pipeline还是view pipeline,还是硬件的流水线


direct hardware access与hosting os runtime
-------------

什么是direct hardware access呢?它是原因还是结果呢?比如,硬件是先有硬件加速的能力,然后dx适应它?还是DX有自己的一套软件方式在先,然后硬件才提供加速的呢?

direct memory access,这说明,去掉中间层 – 硬件抽象层,就是直接,一般硬件,都没有处理作用.像网卡,显卡,声卡这样的东西,其驱动程序往往是很复杂的.比如tcp/ip,前三层在硬件里,后四层在内核中,而显卡与CPU的关系其实是所有设备与CPU中非常微妙的一种,因为显卡自己有处理功能(甚至听说它能当CPU使用,比如nv的一种显卡).而且在显存.我们知道,软件的功能是无所不能,但这是以CPU计算为前提的,如果把显卡自身在硬件级,就能发挥的功能,弄到软件级,那么这就是普通的驱动.内核中的GDI就是一种soft render,

>render同时具有2d处理和3d处理二大功能,比如direct3d中合并了directdraw,directdraw与gdi,一个是soft graphics render based on hal,一个是soft graphics render directly accessing hardware(即越过了hal那一层). 3d图形学是有别于传统图形学的(2d),但是也可以采用一些2d的技术基础,而且,道理上,2d的东西,没有道理不可以用3d来完成. 一般地,利用2d接口是怎么样处理图形的呢,比如mfc中的gdi.一般有设备环境,bitblt(),transport(),alpha()这样的东西. 3d中的2d就是用3d的接口来处理图形以达到2d效果(所以实际上,它也是3d的那些处理逻辑,不过,它去除了一些能在真正的3d处理发挥重要地位的api,而取其能很好用于2d的那一部分) 注意,因为3d render把一切都看成图元,因此3d中的2d处理,也是涉及到顶点的(而不是设备场景).因为它把一切,都看成是3d.把2d看成是3d世界中的一种特例. Dx与操作系统的接口,它利用了windows的窗口机制,不像gl一样,没有窗口机制,而且,它还利用了windows的颜色表. 注意:只有在8位颜色的情况下,使用调色板才有意义.(颜色表是颜色表,调色板是调色板)

当然,我们是做不出像dx立既模式那样的3d software render东西的,因为这只需要显卡厂商和驱动程序开发者的支持,我们只能做出纯粹的soft render,不具有硬件直接访问能力的(opengl 本来是一个纯粹的软件渲染,后来发展为需要硬件和厂商支持的库)

cpu上的2D图形表示 用户提供绘图过程 在CPU中表达一条线 在显卡中存储一条线和在屏幕上显示一条线

>你看,这所有的一切,就足够可以形成一个“计算机图形学”了.就计算机图形来说,如果它的意义仅是表现图形本身,那么以上这些(显示器加显存,光栅器能帮助用户完成的所有工作)就足够达到的,或许,它更适合被称为“绘制”,而不是“渲染”. 我们应清楚到看到这二者的区别.因为用户提供绘图指令,只能是在CPU上,三个图形硬件,只能被动地“绘制”(显示器显示,显存存储,光栅扫描).程序员在绘制过程中,并不能得到软件上的更多自由,因为程序员的工作被限制在传统的CPU和CPU编程上.而不能控制显存如何存储更多,光栅化如何扫描得更快,这些算法上的加速(即使以后有更多加速硬件被加到显卡内那也只能表明,有更多在CPU上能完成的新算法得到了硬件上的加速),他们依然不能向这个由显卡组成的“黑盒”定制和增加加速算法. 如果能,那就是渲染.我们把“程序员提供pre-drawing数据到显存”,“程序员为增加在显卡上能工作的新的绘制算法”,“图形硬件体系完成它们自己的事产生一个结果”称为“渲染”,于是pre-drawing变成了pre-rendering. 最初的计算机图形学,就是这么一个范围(显卡中的硬件加速单元只有越来越大的存储部件和越来越快的光栅器).只是后来显卡中集成有更多加速部件,甚至是GPU,后来计算机图形学才演变为一个大系,就图形来说,它的意义是表现图形本身,那么几何物体的表示,跟渲染(它表现的,是一个静态世界,即3d core部分,我们用图形学硬件中的光删化displase和crt作为二大硬件基础.来界定3d core),就足够是图形学了,但是,在使图形变得变好更美的话题上提出了很多其它的技术与技巧(往往是物理的方法),那么它是不是图形学呢,是不是有点VR的味道了呢? 我们首先是3d,然后是交互式3d,但是,往往,3D世界是动画的世界(所以,计算机图形学不妨更合适被称为计算机VR学,因为这里的3d世界,实际上是4d time-space世界).有的需要作碰撞反应,有的就不需要. 目录:1,3d hardware core2,3d thoery core(vr geo,vr math,vr pysic,统一称为数几物,解决vr相关的问题,可以从数几物-based着手,也可以从非数几物着手,比如纯vetex processing和pixel processing),3,3d objects abouts4,reality abouts(matring,texturing,lighting)4.4d spacetime 过程纹理技术可以取代不必要的建模,比如水面效果就不必去用网格描绘

于是出现了3d render的概念.




点阵图形原理，视频原理
-------------

Xxx

点阵字体原理
-------------

Xxxx